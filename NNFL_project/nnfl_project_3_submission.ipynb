{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading word2vec data and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "nE_yc3v_NyN-",
    "outputId": "60cc9640-a9ff-435c-cfe3-b03ceb29b832"
   },
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "XerWRytVN2x-",
    "outputId": "47e760bd-15ea-4026-dbea-64c1a3442527"
   },
   "outputs": [],
   "source": [
    "!unzip glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "GJ8U-kpS9rwf",
    "outputId": "edf520bc-7cca-4e0f-f447-d221248f9f4f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "rCZGkK2J9P-W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from keras.layers import  Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1MOGJXf9P-m"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/content/drive/My Drive/NNFL Fall'19 Project/data_7000_new.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QknlfjzK75ql",
    "outputId": "441ae91c-13de-414a-cc33-54753303914f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "images={}\n",
    "i=0\n",
    "# print(train[0][100])\n",
    "# a=[]\n",
    "not_aval=[]\n",
    "for file in train[0]:\n",
    "  a=cv2.imread(os.path.join(\"/content/drive/My Drive/NNFL Fall'19 Project/data_7000/\", file))\n",
    "  print(i)\n",
    "  if a is not None:\n",
    "    images[i] = cv2.resize(a,(240,240))\n",
    "    # print(a)\n",
    "    i+=1\n",
    "  else:\n",
    "    print(file,i)\n",
    "    i+=1\n",
    "    not_aval.append(i-1)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "4YnzgqWjBokN",
    "outputId": "0481ed5b-8b21-48a6-9498-0b4c739fe8ce"
   },
   "outputs": [],
   "source": [
    "print(train[0][not_aval])\n",
    "trainFinal=train.drop(not_aval,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "3qKRs6zHVyy1",
    "outputId": "1131bdb9-199f-43f7-aabc-270f69bf14ad"
   },
   "outputs": [],
   "source": [
    "trainFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-Vjyw-Rm9P-s",
    "outputId": "4ef8f33a-6b2a-48c5-efb9-0182ec081c1b"
   },
   "outputs": [],
   "source": [
    "x_text=trainFinal[3]\n",
    "x_text.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOaJFndlVn2-"
   },
   "outputs": [],
   "source": [
    "y3=trainFinal[6]\n",
    "y4=trainFinal[7]\n",
    "y5=trainFinal[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eihX5gQv2xgR"
   },
   "outputs": [],
   "source": [
    "\n",
    "a3={}\n",
    "a4={}\n",
    "a5={}\n",
    "\n",
    "for i in y3:\n",
    "  if i in a3.keys():\n",
    "    a3[i]+=1\n",
    "  else:\n",
    "    a3[i]=1\n",
    "for i in y4:\n",
    "  if i in a4.keys():\n",
    "    a4[i]+=1\n",
    "  else:\n",
    "    a4[i]=1\n",
    "for i in y5:\n",
    "  if i in a5.keys():\n",
    "    a5[i]+=1\n",
    "  else:\n",
    "    a5[i]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OSH7XUFBYDr"
   },
   "outputs": [],
   "source": [
    "y4f= y4.replace({\"motivational\":+1, \"not_motivational\":0,'negative':None,'neutral':None,'positive':None,'very_negative':None,'very_positive':None})\n",
    "a4f={}\n",
    "for i in y4f:\n",
    "  if i in a4f.keys():\n",
    "    a4f[i]+=1\n",
    "  else:\n",
    "\n",
    "    a4f[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTGOSrtvVMPH"
   },
   "outputs": [],
   "source": [
    "x_text=x_text.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9Y7pe8ouUPLz",
    "outputId": "b6afddb5-ff22-48ca-c3d9-7d1718d33e4e"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "word_index=[]\n",
    "num_words = 12880\n",
    "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(x_text.values)\n",
    "X = tokenizer.texts_to_sequences(x_text.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "max_length_of_text = 50\n",
    "X = pad_sequences(X, maxlen=max_length_of_text)\n",
    "\n",
    "print(word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "PMorhpHQO63p",
    "outputId": "5e267d23-507d-4462-ae82-10bb91f281a1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "f = open( 'glove.6B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNFOYXI0UzB6"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clGWv90H9P-3"
   },
   "outputs": [],
   "source": [
    "moti_Text=X[y4f.notnull()]\n",
    "moti_images=pd.Series(images)[y4f.notnull()]\n",
    "y4f=y4f[y4f.notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 3 diffrent models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivational or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "colab_type": "code",
    "id": "lANR3PP39P_f",
    "outputId": "bc1c3cca-7c5a-4e41-dc03-ff9a04b80f2f"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution1D as Conv1D\n",
    "from  keras.layers import MaxPooling1D as MaxPooling1D\n",
    "embed_dim = 200 #Change to observe effects\n",
    "lstm_out = 512 #Change to observe effects\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "input1 = keras.layers.Input(shape=(240,240,3,),name=\"image_input\")\n",
    "input2 = keras.layers.Input(shape=(50,),name=\"text_input\")\n",
    "\n",
    "iml=Conv2D(64, (3, 3), activation='relu',name=\"Conv2D_1\")(input1)\n",
    "iml=MaxPool2D(pool_size=(2, 2),name='MaxPool2D_1')(iml)\n",
    "iml=Conv2D(64, (3, 3), activation='relu',name=\"Conv2d_2\")(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2),name=\"MaxPool2D_2\")(iml)\n",
    "\n",
    "iml=Conv2D(128, (3,3), activation='relu',name=\"Conv2D_3\")(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2),name=\"MaxPool2D_3\")(iml)\n",
    "\n",
    "iml = Flatten(name=\"Flatten_images\")(iml)\n",
    "\n",
    "x = Embedding(12881, embed_dim,weights=[embedding_matrix],name=\"Embedding_layer\")(input2)  \n",
    "x = Conv1D(512, 5, activation='relu', kernel_initializer='normal',name=\"Conv1D_1\")(x)\n",
    "x = Conv1D(256, 5, activation='relu', kernel_initializer='normal',name=\"Conv1D_2\")(x)\n",
    "x = MaxPooling1D(5,name=\"MaxPooling1D_text\")(x)\n",
    "x = Flatten(name=\"Flatten_text\")(x)\n",
    "added=keras.layers.Concatenate(axis=-1)([x,iml])\n",
    "x= Dense(128,activation='relu', kernel_initializer='normal',name=\"Dense_1\")(added)\n",
    "preds = Dense(1, activation='sigmoid', kernel_initializer='normal',name=\"Dense_2\")(x)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGxgkwZd9P-9"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6IJuTFy21E2"
   },
   "outputs": [],
   "source": [
    "y4final=y4f\n",
    "moti_train_text,moti_test_text,moti_train_image,moti_test_image, y_moti_train, y_moti_test = train_test_split(moti_Text,moti_images,y4final,test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "DIUw-6892af_",
    "outputId": "55ad94b5-f060-423f-aa3d-8d80d1abd30f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSpHTsyuj8TE"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHuYW17l9P_q"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics = ['mae','accuracy',f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twWUv27SJPTg"
   },
   "outputs": [],
   "source": [
    "\n",
    "moti_train_image=np.array(moti_train_image.tolist())\n",
    "moti_test_image=np.array(moti_test_image.tolist())\n",
    "moti_train_image=np.true_divide(moti_train_image,255)\n",
    "moti_test_image=np.true_divide(moti_test_image,255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "ca1p0JzB9Ulk",
    "outputId": "08c5990a-bf43-46d4-83df-d390e8f94ade"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "cv2_imshow( np.multiply(moti_train_image[0],255));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DzDkvtRy9P_0",
    "outputId": "b0cd2d6c-1ff6-4e5c-df87-810d690db3a4"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement.hdf5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(x=[moti_train_image,moti_train_text], y=y_moti_train, batch_size=32, epochs=50,callbacks=callbacks_list, verbose=1,validation_data=([moti_test_image,moti_test_text],y_moti_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpKxG8znoMty"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-improvement.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGy3f2oehT8J"
   },
   "outputs": [],
   "source": [
    "y_predicted=model.predict([moti_test_image,moti_test_text])\n",
    "y_predicted=y_predicted.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "SaVfIIv5okH6",
    "outputId": "e880add1-9c5e-44d9-d2ab-eee58152bcf8"
   },
   "outputs": [],
   "source": [
    "ans=[]\n",
    "for i in y_predicted:\n",
    "  if i>=.5:\n",
    "    ans.append(1)\n",
    "  else:\n",
    "    ans.append(0)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HuODxsxNUaS-",
    "outputId": "090b9a69-753f-4055-ee76-dc0d60d5bb49"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "rjCEaNlCVGri",
    "outputId": "ae60ac8a-cee0-440b-8eb8-f7179c79943d"
   },
   "outputs": [],
   "source": [
    "y5f= y5.replace({'negative': 1,'neutral': 2,'positive': 3,'positivechandler_Friday-Mood-AF.-meme-Friends-ChandlerBing.jpg':3,'very_negative': 0,'very_positive': 4})\n",
    "a5f={}\n",
    "for i in y5f:\n",
    "  if i in a5f.keys():\n",
    "    a5f[i]+=1\n",
    "  else:\n",
    "    a5f[i]=1\n",
    "print(a5f)\n",
    "\n",
    "y3f= y3.replace({'hateful_offensive': 3,'very_offensive': 2,'slight': 1,'not_offensive': 0,'very_positive':None,'motivational': None,'not_motivational':None,'positive':None})\n",
    "y3fmean=y3f.mean()\n",
    "# y3f=y3f.fillna(y3fmean)\n",
    "a3f={}\n",
    "for i in y3f:\n",
    "  if i in a3f.keys():\n",
    "    a3f[i]+=1\n",
    "  else:\n",
    "    a3f[i]=1\n",
    "print(a3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22c-XSo3Za6Q"
   },
   "source": [
    "# offensive or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wv1UuqsqJsh2"
   },
   "outputs": [],
   "source": [
    "pos_text=X[y5f.notnull()]\n",
    "pos_images=pd.Series(images)[y5f.notnull()]\n",
    "y5f=y5f[y5f.notnull()]\n",
    "\n",
    "offensive_Text=X[y3f.notnull()]\n",
    "offensive_images=pd.Series(images)[y3f.notnull()]\n",
    "y3f=y3f[y3f.notnull()]\n",
    "\n",
    "off_train_text,off_test_text,off_train_image,off_test_image, y3_off_train, y3_off_test = train_test_split(offensive_Text,offensive_images,y3f,test_size = 0.1)\n",
    "pos_train_text,pos_test_text,pos_train_image,pos_test_image, y5_pos_train, y5_pos_test = train_test_split(pos_text,pos_images,y5f,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuzsyjeVUqa9"
   },
   "outputs": [],
   "source": [
    "off_train_image=np.array(off_train_image.tolist())\n",
    "off_test_image=np.array(off_test_image.tolist())\n",
    "off_train_image=np.true_divide(off_train_image,255)\n",
    "off_test_image=np.true_divide(off_test_image,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5W-kyP1jNdVk"
   },
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "embed_dim = 200 #Change to observe effects\n",
    "lstm_out = 512 #Change to observe effects\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "input1 = keras.layers.Input(shape=(240,240,3,))\n",
    "input2 = keras.layers.Input(shape=(50,))\n",
    "\n",
    "iml=Conv2D(64, (3, 3), activation='relu')(input1)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "iml=Conv2D(64, (3, 3), activation='relu')(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "iml=Conv2D(128, (3,3), activation='relu')(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "\n",
    "iml = Flatten()(iml)\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution1D as Conv1D\n",
    "from  keras.layers import MaxPooling1D as MaxPooling1D\n",
    "x = Embedding(12881, embed_dim,weights=[embedding_matrix])(input2)  \n",
    "x = Conv1D(512, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = Conv1D(256, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "added=keras.layers.Concatenate(axis=-1)([x,iml])\n",
    "x=Dropout(0.1)(x)\n",
    "x= Dense(128,activation='relu', kernel_initializer='normal')(added)\n",
    "\n",
    "preds = Dense(1, activation='linear', kernel_initializer='normal')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=preds)\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igTGztVm4o7Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='sgd', metrics = ['mae','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wxSHDXuGaiF"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "\n",
    "  def __init__(self, valid_data, *args, **kwargs):\n",
    "    self.valid_data = valid_data\n",
    "\n",
    "    super(Metrics, self).__init__(*args, **kwargs)\n",
    "\n",
    "  def on_train_begin(self, logs={}):\n",
    "    pass\n",
    "  \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    global temp\n",
    "    val_predict =self.model.predict(self.valid_data[0])\n",
    "    val_targ =self.valid_data[1]\n",
    "    \n",
    "    _val_f1 = f1_score(val_targ, np.round(val_predict), average = 'macro')\n",
    "    print(\" — val_macro_f1: {}\".format(_val_f1))\n",
    "    return\n",
    "\n",
    "metric = Metrics(([off_test_image,off_test_text],y3_off_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B70ixEulZ55D",
    "outputId": "df54cd95-68f8-4e00-dca4-550e08880fe3"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement\"\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}.hdf5', monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint,metric]\n",
    "\n",
    "model.fit(x=[off_train_image,off_train_text], y=y3_off_train, batch_size=32, epochs=30,callbacks=callbacks_list, verbose=1,validation_data=([off_test_image,off_test_text],y3_off_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOtqJp7Aa06z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHPMKTUAhoJ7"
   },
   "source": [
    "# positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjhWkW7AWYzf"
   },
   "outputs": [],
   "source": [
    "pos_train_image=np.array(pos_train_image.tolist())\n",
    "pos_test_image=np.array(pos_test_image.tolist())\n",
    "pos_train_image=np.true_divide(pos_train_image,255)\n",
    "pos_test_image=np.true_divide(pos_test_image,255)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "YNzRZG4GhsT8",
    "outputId": "41711b8a-3655-438c-dc39-a4ba25bb00e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "embed_dim = 200 #Change to observe effects\n",
    "lstm_out = 512 #Change to observe effects\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "input1 = keras.layers.Input(shape=(240,240,3,))\n",
    "input2 = keras.layers.Input(shape=(50,))\n",
    "\n",
    "iml=Conv2D(64, (3, 3), activation='relu')(input1)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "iml=Conv2D(64, (3, 3), activation='relu')(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "iml=Conv2D(128, (3,3), activation='relu')(iml)\n",
    "iml=MaxPool2D(pool_size=(2, 2))(iml)\n",
    "\n",
    "\n",
    "iml = Flatten()(iml)\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution1D as Conv1D\n",
    "from  keras.layers import MaxPooling1D as MaxPooling1D\n",
    "x = Embedding(12881, embed_dim,weights=[embedding_matrix])(input2)  \n",
    "x = Conv1D(512, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = Conv1D(256, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu', kernel_initializer='normal')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "added=keras.layers.Concatenate(axis=-1)([x,iml])\n",
    "x= Dense(128,activation='relu', kernel_initializer='normal')(added)\n",
    "preds = Dense(1, activation='linear', kernel_initializer='normal')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=preds)\n",
    "\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "odERFsICiN0z",
    "outputId": "a15af9f2-d601-4d02-b255-b04d8ad53796"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'mae', optimizer=\"sgd\", metrics = ['mae','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Axk5TOrXiRea",
    "outputId": "d809e4a5-6f73-4127-ce24-99e3e490051d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement.hdf5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_absolute_error', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(x=[pos_train_image,pos_train_text], y=y5_pos_train, batch_size=32, epochs=120,callbacks=callbacks_list, verbose=1,validation_data=([pos_test_image,pos_test_text],y5_pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vAtLW6t-ieOc",
    "outputId": "fe675c80-069c-41de-e7b9-6e39c8894dc8"
   },
   "outputs": [],
   "source": [
    " min(model.predict([pos_train_image,pos_train_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h3x05HxHjtTc",
    "outputId": "2d95ec47-670f-4251-87a6-e961e69034af"
   },
   "outputs": [],
   "source": [
    "np.max(y5_pos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UMJMPPSkc2g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "nnfl project 3 final",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
